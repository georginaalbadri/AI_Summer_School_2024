{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from google.colab.patches import cv2_imshow\n",
    "from transformers import pipeline\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Language Processing\n",
    "Application: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained sentiment analysis pipeline from Hugging Face\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text data\n",
    "texts = [\n",
    "    \"I love sunny days!\",\n",
    "    \"I hate when it rains all day.\",\n",
    "    \"The weather is just perfect.\",\n",
    "    \"I'm feeling quite sad today.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sentiment analysis on each text\n",
    "results = sentiment_analysis(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the texts and their sentiment results\n",
    "for text, result in zip(texts, results):\n",
    "    print(f\"Text: {text}\\nSentiment: {result['label']} (Score: {result['score']})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Computer Vision\n",
    "Application: Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and display an image\n",
    "def display_image(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return img, np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained object detection model from TensorFlow Hub\n",
    "detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example image URL\n",
    "image_url = \"https://images.unsplash.com/photo-1593642532973-d31b6557fa68\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "img, imgarray = display_image(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to a tensor\n",
    "img = img.resize((640, 480))  # Resize to match model's expected input size\n",
    "img_tensor = tf.convert_to_tensor(np.array(img), dtype=tf.uint8)\n",
    "img_tensor = tf.expand_dims(img_tensor, axis=0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the object detection model\n",
    "result = detector(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw bounding boxes on the image\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.5):\n",
    "    colors = list(plt.cm.tab20(np.linspace(0, 1, 20)))\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for i in range(min(max_boxes, boxes.shape[0])):\n",
    "        if scores[i] >= min_score:\n",
    "            color = colors[int(class_names[i]) % len(colors)]\n",
    "            ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "            image = cv2.rectangle(image, (int(xmin * img.width), int(ymin * img.height)),\n",
    "                                  (int(xmax * img.width), int(ymax * img.height)), color, 2)\n",
    "            image = cv2.putText(image, str(int(class_names[i])), (int(xmin * img.width), int(ymin * img.height) - 10),\n",
    "                                font, 0.5, color, 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract detection results\n",
    "boxes = result[\"detection_boxes\"][0].numpy()\n",
    "class_names = result[\"detection_classes\"][0].numpy()\n",
    "scores = result[\"detection_scores\"][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding boxes on the image\n",
    "output_img = draw_boxes(np.array(img), boxes, class_names, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image with bounding boxes\n",
    "cv2_imshow(output_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Computer Vision\n",
    "Applicaton: Style transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained style transfer model from TensorFlow Hub\n",
    "style_transfer_model = hub.load(\"https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content and style image URLs\n",
    "content_image_url = \"https://thumbs.dreamstime.com/b/beautiful-happy-reddish-havanese-puppy-dog-sitting-frontal-looking-camera-isolated-white-background-46868560.jpg\"\n",
    "style_image_url = \"https://sanctuarymentalhealth.org/wp-content/uploads/2021/03/The-Starry-Night-1200x630-1-979x514.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and load content and style images\n",
    "content_img, content_array = display_image(content_image_url)\n",
    "style_img, style_array = display_image(style_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images for the model\n",
    "content_image = tf.convert_to_tensor(content_array, dtype=tf.float32)\n",
    "content_image = tf.image.resize(content_image, (256, 256)) / 255.0\n",
    "content_image = tf.expand_dims(content_image, axis=0\n",
    "                               \n",
    "style_image = tf.convert_to_tensor(style_array, dtype=tf.float32)\n",
    "style_image = tf.image.resize(style_image, (256, 256)) / 255.0\n",
    "style_image = tf.expand_dims(style_image, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform style transfer\n",
    "stylized_image = style_transfer_model(tf.constant(content_image), tf.constant(style_image))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the stylized image\n",
    "plt.imshow(stylized_image[0])\n",
    "plt.title('Stylized Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Language Processing\n",
    "Applicaton: Similarity detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text data\n",
    "text1 = \"AI is transforming the world.\"\n",
    "text2 = \"Artificial intelligence is changing everything.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to embeddings\n",
    "embedding1 = sentiment_model([text1])[0]\n",
    "embedding2 = sentiment_model([text2])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between the two texts\n",
    "similarity = cosine_similarity([embedding1], [embedding2])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the texts and their similarity score\n",
    "print(f\"Text 1: {text1}\\nText 2: {text2}\\nSimilarity Score: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're not already familiar with it, try out DALL-E image generation \\\n",
    "https://openai.com/index/dall-e-3/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And ChatGPT \\\n",
    "https://chatgpt.com/ \\\n",
    "A fun exercise is to ask questions, or to complete tasks, within different contexts, e.g. 'you are a student', 'you are a teacher', 'you are a professional', etc, and see how the responses change. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
