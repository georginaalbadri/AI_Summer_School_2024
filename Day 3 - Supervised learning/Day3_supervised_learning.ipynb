{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNTESTED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset\n",
    "Housing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c house-prices-advanced-regression-techniques\n",
    "!unzip house-prices-advanced-regression-techniques.zip\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows and basic information about the dataset\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot relationship between chosen features and target variable\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='GrLivArea', y='SalePrice', data=df)\n",
    "plt.title('Relationship between GrLivArea (Above Grade Living Area) and Sale Price')\n",
    "plt.xlabel('GrLivArea')\n",
    "plt.ylabel('Sale Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, plot relationship between all features and target variable, by computing the correlations between variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, and to use all the features in the dataset, we need to make sure that all the features are numerical. We can do this by converting all the categorical features to numerical using one-hot encoding. We can then drop the original categorical features. We can also drop the Id column as it is not useful for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify non-numeric columns\n",
    "non_numeric_columns = df.select_dtypes(include=['object']).columns\n",
    "print(\"Non-numeric columns:\", non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert non-numeric columns using one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=non_numeric_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Id column\n",
    "df_encoded.drop('Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get correlation between variables with respect to SalePrice\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m correlation \u001b[38;5;241m=\u001b[39m \u001b[43mdf_encoded\u001b[49m\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[1;32m      3\u001b[0m top_corr \u001b[38;5;241m=\u001b[39m correlation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalePrice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[:\u001b[38;5;241m20\u001b[39m]\n\u001b[1;32m      4\u001b[0m top_corr\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "# Get correlation between variables with respect to SalePrice\n",
    "correlation = df_encoded.corr()\n",
    "top_corr = correlation['SalePrice'].sort_values(ascending=False)[:20]\n",
    "top_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap of correlation matrix for top 10 correlated features\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation.loc[top_corr.index, top_corr.index], annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Top 10 Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the correlation matrix, you can see which features are correlated with the SalePrice, and which features are correlated with each other to identify dependent and independent variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with more than 50% missing values\n",
    "df_cleaned = df.dropna(thresh=0.5*len(df), axis=1)\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target variable, e.g. \n",
    "X = df_cleaned[['GrLivArea', 'YearBuilt']]\n",
    "y = df_cleaned['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables (if not already done)\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into test and training sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regression models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    print(f\"R^2 Score: {r2:.2f}\")\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models visually\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    plt.scatter(y_test, y_pred, label=name)\n",
    "plt.xlabel('Actual Sale Price')\n",
    "plt.ylabel('Predicted Sale Price')\n",
    "plt.title('Actual vs Predicted Sale Prices')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Discuss model performance and selection criteria (e.g., MSE, R^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: optimise model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the models again with hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameters for Decision Tree\n",
    "param_grid_dt = {\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Grid Search for Decision Tree\n",
    "grid_search_dt = GridSearchCV(DecisionTreeRegressor(random_state=42), param_grid_dt, cv=5)\n",
    "grid_search_dt.fit(X_train_scaled, y_train)\n",
    "best_dt = grid_search_dt.best_estimator_\n",
    "y_pred_dt = best_dt.predict(X_test_scaled)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree:\")\n",
    "print(f\"Best Parameters: {grid_search_dt.best_params_}\")\n",
    "print(f\"Mean Squared Error: {mse_dt:.2f}\")\n",
    "print(f\"R^2 Score: {r2_dt:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Grid Search for Random Forest\n",
    "grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X_train_scaled, y_train)\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test_scaled)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest:\")\n",
    "print(f\"Best Parameters: {grid_search_rf.best_params_}\")\n",
    "print(f\"Mean Squared Error: {mse_rf:.2f}\")\n",
    "print(f\"R^2 Score: {r2_rf:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
