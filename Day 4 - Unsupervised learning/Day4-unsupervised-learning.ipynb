{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and dimensionality reduction of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style in seaborn\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we load Colab, we need to upload our kaggle.json file to access the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we need to move the kaggle.json file to the expected location  \n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Mall Customers dataset\n",
    "!kaggle datasets download -d vjchoudhary7/customer-segmentation-tutorial-in-python\n",
    "\n",
    "# Unzip the downloaded dataset\n",
    "!unzip customer-segmentation-tutorial-in-python.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure and summary of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get % of missing values in each column\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0] # Only look at columns with missing values\n",
    "missing_percentage = missing / df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove customers with more than 50% missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise correlation matrix using heatmap\n",
    "# This shows which features are related to each other \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for clustering, e.g. Annual Income, Spending Score\n",
    "features = ['Annual Income (k$)', 'Spending Score (1-100)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the number of clusters, k\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering\n",
    "kmeans = KMeans(n_clusters=k, \n",
    "                random_state=42) # Set random state for reproducibility\n",
    "\n",
    "kmeans_labels = kmeans.fit_predict(df_scaled) # Fit the model and predict the clusters\n",
    "\n",
    "df['KMeans_Labels'] = kmeans_labels # Add the labels to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize K-Means Clusters\n",
    "plt.figure(figsize=(10, 6)) # Set the figure size for better visualization\n",
    "\n",
    "sns.scatterplot(x=df['Annual Income (k$)'], y=df['Spending Score (1-100)'], hue=kmeans_labels, palette='viridis') # Create a scatter plot in seaborn\n",
    "\n",
    "plt.title('K-Means Clustering') # Set the title of the plot\n",
    "plt.xlabel('Annual Income (k$)') # Set the x-axis label\n",
    "plt.ylabel('Spending Score (1-100)') # Set the y-axis label\n",
    "plt.legend(title='Clusters') # Add a legend to the plot\n",
    "\n",
    "plt.show() # Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters in 3D\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(df['Annual Income (k$)'], df['Spending Score (1-100)'], df['Age'], c=kmeans_labels, cmap='viridis')\n",
    "\n",
    "ax.set_xlabel('Annual Income (k$)')\n",
    "ax.set_ylabel('Spending Score (1-100)')\n",
    "ax.set_zlabel('Age')\n",
    "\n",
    "plt.title('K-Means Clustering in 3D')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have used 2 features (annual income and spending score) so our clusters are in 2D and easy to visualise. If you want to use more than 2 features, you can visualise them in a more limited way by "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of clusters for Agglomerative Clustering\n",
    "n = 5 # Number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Clustering\n",
    "hierarchical = AgglomerativeClustering(n_clusters=n) # Create an instance of the model\n",
    "\n",
    "hierarchical_labels = hierarchical.fit_predict(df_scaled) # Fit the model and predict the clusters\n",
    "\n",
    "df['Hierarchical_Labels'] = hierarchical_labels # Add the labels to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Hierarchical Clusters\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df['Annual Income (k$)'], y=df['Spending Score (1-100)'], hue=hierarchical_labels, palette='viridis') # Create a scatter plot in seaborn\n",
    "plt.title('Hierarchical Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN Clustering\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5) # Create an instance of the model with parameters eps and min_samples \n",
    "dbscan_labels = dbscan.fit_predict(df_scaled) # Fit the model and predict the clusters\n",
    "df['DBSCAN_Labels'] = dbscan_labels # Add the labels to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DBSCAN Clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df['Annual Income (k$)'], y=df['Spending Score (1-100)'], hue=dbscan_labels, palette='viridis')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the silhoette score which measures how similar a data point is to its own cluster compared to other clusters. Values range from -1 to 1, with higher values indicating better-defined clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calculate the silhouette score for K-Means Clustering\n",
    "silhouette_kmeans = silhouette_score(df_scaled, kmeans_labels)\n",
    "print(f'Silhouette Score for K-Means Clustering: {silhouette_kmeans}')\n",
    "\n",
    "# Calculate the silhouette score for Hierarchical Clustering\n",
    "silhouette_hierarchical = silhouette_score(df_scaled, hierarchical_labels)\n",
    "print(f'Silhouette Score for Hierarchical Clustering: {silhouette_hierarchical}')\n",
    "\n",
    "# Calculate the silhouette score for DBSCAN Clustering\n",
    "silhouette_dbscan = silhouette_score(df_scaled, dbscan_labels)\n",
    "print(f'Silhouette Score for DBSCAN Clustering: {silhouette_dbscan}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction\n",
    "Let's take all the features, and use PCA (Principal Component Analysis) to find the axis of greatest variation and project the data onto 2D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2) # Create an instance of the PCA model with 2 components\n",
    "pca_components = pca.fit_transform(df_scaled) # Fit the model and transform the data\n",
    "\n",
    "df['PCA1'] = pca_components[:, 0] # Add the first component to the original dataset\n",
    "df['PCA2'] = pca_components[:, 1] # Add the second component to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PCA Components\n",
    "plt.figure(figsize=(10, 6)) # Set the figure size for better visualization\n",
    "sns.scatterplot(x=df['PCA1'], y=df['PCA2'], hue=kmeans_labels, palette='viridis') # Create a scatter plot in seaborn\n",
    "plt.title('PCA - K-Means Clustering') # Set the title of the plot\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
