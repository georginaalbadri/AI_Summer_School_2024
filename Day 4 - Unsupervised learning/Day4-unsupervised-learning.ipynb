{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and dimensionality reduction of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style in seaborn\n",
    "sns.set(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we load Colab, we need to upload our kaggle.json file to access the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we need to move the kaggle.json file to the expected location  \n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Mall Customers dataset\n",
    "!kaggle datasets download -d vjchoudhary7/customer-segmentation-tutorial-in-python\n",
    "\n",
    "# Unzip the downloaded dataset\n",
    "!unzip customer-segmentation-tutorial-in-python.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset of Mall Customers\n",
    "df = pd.read_csv('Mall_Customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure and summary of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values - this dataset looks clean! Do you want to check anything else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In df.info(), we can see that the column 'Gender' has dtype 'object', which means it's non numerical.\n",
    "# Apply one-hot-encoding to make this data numerical\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will drop the column 'customer ID' because it is not a real/useful feature\n",
    "df = df.drop('CustomerID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise correlation matrix using heatmap\n",
    "# This shows which features are related to each other \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the correlation matrix that Age and Spending Score are negatively correlated (-0.33). Otherwise, there are not many correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for clustering, e.g. Annual Income, Spending Score - try different options, including 3 if you want (see 3D visualisation below)\n",
    "features = ['Annual Income (k$)', 'Spending Score (1-100)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the number of clusters, k\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering\n",
    "kmeans = KMeans(n_clusters=k, \n",
    "                random_state=42) # Set random state for reproducibility\n",
    "\n",
    "kmeans_labels = kmeans.fit_predict(df_scaled) # Fit the model and predict the clusters\n",
    "\n",
    "df['KMeans_Labels'] = kmeans_labels # Add the labels to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize K-Means Clusters\n",
    "plt.figure(figsize=(10, 6)) # Set the figure size for better visualization\n",
    "\n",
    "sns.scatterplot(x=df['Annual Income (k$)'], y=df['Spending Score (1-100)'], hue=kmeans_labels, palette='viridis') # Create a scatter plot in seaborn\n",
    "\n",
    "plt.title('K-Means Clustering') # Set the title of the plot\n",
    "plt.xlabel('Annual Income (k$)') # Set the x-axis label\n",
    "plt.ylabel('Spending Score (1-100)') # Set the y-axis label\n",
    "plt.legend(title='Clusters') # Add a legend to the plot\n",
    "\n",
    "plt.show() # Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional - if you chose to use 3 features - visualize the clusters in 3D (remove # on each line to run this bit of code)\n",
    "# fig = plt.figure(figsize=(10, 6))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# \n",
    "# # Change 'Annual Income, 'Spending Score', 'Age' to whichever 3 features you chose\n",
    "# ax.scatter(df['Annual Income (k$)'], df['Spending Score (1-100)'], df['Age'], c=kmeans_labels, cmap='viridis')\n",
    "# \n",
    "# ax.set_xlabel('Annual Income (k$)')\n",
    "# ax.set_ylabel('Spending Score (1-100)')\n",
    "# ax.set_zlabel('Age')\n",
    "# \n",
    "# plt.title('K-Means Clustering in 3D')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of clusters for Agglomerative Clustering\n",
    "n = 5 # Number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Clustering\n",
    "hierarchical = AgglomerativeClustering(n_clusters=n) # Create an instance of the model\n",
    "\n",
    "hierarchical_labels = hierarchical.fit_predict(df_scaled) # Fit the model and predict the clusters\n",
    "\n",
    "df['Hierarchical_Labels'] = hierarchical_labels # Add the labels to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Hierarchical Clusters\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df['Annual Income (k$)'], y=df['Spending Score (1-100)'], hue=hierarchical_labels, palette='viridis') # Create a scatter plot in seaborn\n",
    "plt.title('Hierarchical Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compare the clustering from k-means and hierarchical, can you see any difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN Clustering\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5) # Create an instance of the model with parameters eps and min_samples \n",
    "dbscan_labels = dbscan.fit_predict(df_scaled) # Fit the model and predict the clusters\n",
    "df['DBSCAN_Labels'] = dbscan_labels # Add the labels to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DBSCAN Clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df['Annual Income (k$)'], y=df['Spending Score (1-100)'], hue=dbscan_labels, palette='viridis')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clustering doesn't look as good. Can you change the parameters eps and min_samples to improve it? \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html\n",
    "\n",
    "Why might DBSCAN not perform so well for this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the silhoette score which measures how similar a data point is to its own cluster compared to other clusters. Values range from -1 to 1, with higher values indicating better-defined clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calculate the silhouette score for K-Means Clustering\n",
    "silhouette_kmeans = silhouette_score(df_scaled, kmeans_labels)\n",
    "print(f'Silhouette Score for K-Means Clustering: {silhouette_kmeans}')\n",
    "\n",
    "# Calculate the silhouette score for Hierarchical Clustering\n",
    "silhouette_hierarchical = silhouette_score(df_scaled, hierarchical_labels)\n",
    "print(f'Silhouette Score for Hierarchical Clustering: {silhouette_hierarchical}')\n",
    "\n",
    "# Calculate the silhouette score for DBSCAN Clustering\n",
    "silhouette_dbscan = silhouette_score(df_scaled, dbscan_labels)\n",
    "print(f'Silhouette Score for DBSCAN Clustering: {silhouette_dbscan}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction\n",
    "Let's take all the features, and use PCA (Principal Component Analysis) to find the axis of greatest variation and project the data onto 2D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2) # Create an instance of the PCA model with 2 components\n",
    "pca_components = pca.fit_transform(df_scaled) # Fit the model and transform the data\n",
    "\n",
    "df['PCA1'] = pca_components[:, 0] # Add the first component to the original dataset\n",
    "df['PCA2'] = pca_components[:, 1] # Add the second component to the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PCA Components\n",
    "plt.figure(figsize=(10, 6)) # Set the figure size for better visualization\n",
    "sns.scatterplot(x=df['PCA1'], y=df['PCA2']) # Create a scatter plot in seaborn\n",
    "plt.title('PCA') # Set the title of the plot\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using PCA, our data (with all features) has been projected onto 2D which will make clustering and visualisation much easier. \n",
    "\n",
    "Let's do k-means clustering on this 2D projection of our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means on PCA1 and PCA2 as features\n",
    "pca_features = ['PCA1', 'PCA2']\n",
    "pca_df = df[pca_features]\n",
    "\n",
    "pca_scaler = StandardScaler()\n",
    "pca_scaled = pca_scaler.fit_transform(pca_df)\n",
    "\n",
    "pca_kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "pca_kmeans_labels = pca_kmeans.fit_predict(pca_scaled)\n",
    "\n",
    "df['PCA_KMeans_Labels'] = pca_kmeans_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise PCA with k-means clustering \n",
    "sns.scatterplot(x=df['PCA1'], y=df['PCA2'], hue=pca_kmeans_labels, palette='viridis') # Scatter plot coloured by k_means labels\n",
    "plt.title('K-Means Clustering')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data splits nicely into 5 clusters when considering all features. Let's look at which type of customer these clusters represent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean values of each column, grouped by KMeans_Labels cluster number\n",
    "df.groupby('KMeans_Labels').mean()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
